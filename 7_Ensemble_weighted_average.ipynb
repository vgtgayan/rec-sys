{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "dd5bc4e9-a5bb-42ab-8665-c69643530e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "from implicit.datasets.lastfm import get_lastfm\n",
    "from implicit.nearest_neighbours import bm25_weight, BM25Recommender\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from implicit.cpu.bpr import BayesianPersonalizedRanking\n",
    "from implicit.recommender_base import RecommenderBase\n",
    "from implicit import evaluation\n",
    "from utils import pandas_df_to_csr\n",
    "import json\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "ebd54222-a876-4b50-8d6d-0247ee2e82c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "BPR_WEIGHT = 1\n",
    "ALS_WEIGHT = 1\n",
    "BM25_WEIGHT = 0.5\n",
    "K = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf46a535-d50b-4011-aaee-be50ab9afc46",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdb85427-a85a-4666-bd51-90ab0387f850",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_beauty_df = pd.read_csv(\"ratings_Beauty.csv\")\n",
    "user_map, item_map, amazon_beauty_csr = pandas_df_to_csr(amazon_beauty_df)\n",
    "# amazon_beauty_csr_bm25 = bm25_weight(amazon_beauty_csr, K1=100, B=0.8).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f314d047-348d-401d-93cc-e86d87b7c969",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_beauty_coo_bm25 = bm25_weight(amazon_beauty_csr, K1=100, B=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b0967290-a4bc-4ba6-860f-842e455b98f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 1618938 \n",
      " Test size: 404132\n"
     ]
    }
   ],
   "source": [
    "# Test-Train Split\n",
    "train_csr, test_csr = evaluation.train_test_split(amazon_beauty_coo_bm25, train_percentage=0.8, random_state=55)\n",
    "print(f\"Train size: {train_csr.size} \\n Test size: {test_csr.size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9cdbdcaa-fb2a-483c-b7ab-28e719c4bf7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x249274 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csr[userid]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6a297a-aaa8-4431-9019-ec3585fc3336",
   "metadata": {},
   "source": [
    "### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "de7b3ae7-a1e0-490c-8d55-9d031c3dae63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15/15 [21:47<00:00, 87.17s/it]\n"
     ]
    }
   ],
   "source": [
    "ALS_model = AlternatingLeastSquares(factors=128, regularization=0.1, alpha=3.0)\n",
    "ALS_model.fit(train_csr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "24af40f6-3187-434a-83be-cfd880408c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALS_model = AlternatingLeastSquares.load(\"4_CF_ALS_implicit\")\n",
    "BPR_model = BayesianPersonalizedRanking.load(\"5_CF_BPR_implicit\")\n",
    "BM25_model = BM25Recommender.load(\"6_BM25\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7111e519-eadc-47c3-aa66-7e74f8401b88",
   "metadata": {},
   "source": [
    "### Inference - Single User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "90ff8285-7dc9-4b78-847a-845d8d7f16d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get recommendations for the a single user\n",
    "userid = 1\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6cdda30e-c2a1-4b13-a170-66542d5dd232",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BM25': {'ids': [], 'scores': [], 'weight': 1},\n",
       " 'BPR': {42: {'ids': [69377,\n",
       "    47485,\n",
       "    112057,\n",
       "    17612,\n",
       "    13646,\n",
       "    125764,\n",
       "    99864,\n",
       "    91742,\n",
       "    210894,\n",
       "    51510],\n",
       "   'scores': [1.0161221,\n",
       "    0.93109715,\n",
       "    0.92633134,\n",
       "    0.8856752,\n",
       "    0.8801099,\n",
       "    0.86598194,\n",
       "    0.8624427,\n",
       "    0.84489995,\n",
       "    0.8358341,\n",
       "    0.8277712]},\n",
       "  'weight': 1}}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids, scores = BPR_model.recommend(userid, train_csr[userid], N=K, filter_already_liked_items=False)\n",
    "user_dict = {}\n",
    "user_dict[userid] = {\"ids\": list(ids), \"scores\": list(scores)}\n",
    "results[\"BPR\"] = user_dict\n",
    "results[\"BPR\"][\"weight\"] = 1\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "7d60c56d-b508-494d-a791-da3ea1fc04af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ALS': {'ids': [9, 8, 7, 6, 5, 4, 3, 2, 1, 0],\n",
       "  'scores': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "  'weight': 1}}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids, scores = ALS_model.recommend(userid, test_csr[userid], N=K, filter_already_liked_items=False)\n",
    "results[\"ALS\"] = {\"ids\": list(ids), \"scores\": list(scores)} \n",
    "results[\"ALS\"][\"weight\"] = 1\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f4a6e8ca-99ac-4952-a34f-7b41380c6234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BM25': {'ids': [], 'scores': [], 'weight': 1}}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids, scores = BM25_model.recommend(userid, test_csr[userid], N=K, filter_already_liked_items=False)\n",
    "results[\"BM25\"] = {\"ids\": list(ids), \"scores\": list(scores)} \n",
    "results[\"BM25\"][\"weight\"] = 1\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "93c4f168-e95e-45b3-a9c1-a2a5c96a6d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(arr, t_min=0, t_max=1):\n",
    "    norm_arr = []\n",
    "    diff = t_max - t_min\n",
    "    diff_arr = max(arr) - min(arr)   \n",
    "    for i in arr:\n",
    "        temp = (((i - min(arr))*diff)/diff_arr) + t_min\n",
    "        norm_arr.append(temp)\n",
    "    return norm_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "73cc934a-6c24-4a89-8852-587f9181f232",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by_score(x):\n",
    "    return dict(sorted(x.items(), reverse=True, key=lambda item: item[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3cff53d6-b0e7-4f0a-a645-39571df6df66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  BPR\n",
      "[1.0, 0.39893320051043213, 0.3034629072782572, 0.18899484393359542, 0.15168046489629314, 0.07546122116979978, 0.07241763199805365, 0.041353837364369185, 0.032233358378842426, 0.0]\n",
      "Model:  BM25\n",
      "[1.0, 0.6369881469882088, 0.0655036698212032, 0.06547735511979227, 0.012015765006171138, 0.0036333745798613577, 0.001721750771982628, 0.0013743951596270217, 0.0002476635338376557, 0.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{69377: 1.0,\n",
       " 81854: 1.0,\n",
       " 154092: 0.6369881469882088,\n",
       " 13646: 0.39893320051043213,\n",
       " 47485: 0.3034629072782572,\n",
       " 17612: 0.18899484393359542,\n",
       " 125764: 0.15168046489629314,\n",
       " 239507: 0.07546122116979978,\n",
       " 99864: 0.07241763199805365,\n",
       " 0: 0.0655036698212032,\n",
       " 89013: 0.06547735511979227,\n",
       " 112057: 0.041353837364369185,\n",
       " 166611: 0.032233358378842426,\n",
       " 154097: 0.012015765006171138,\n",
       " 154084: 0.0036333745798613577,\n",
       " 154078: 0.001721750771982628,\n",
       " 137641: 0.0013743951596270217,\n",
       " 112431: 0.0002476635338376557,\n",
       " 91742: 0.0,\n",
       " 196064: 0.0}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_results = {}\n",
    "for _model, _results in results.items():\n",
    "    print(\"Model: \",_model)\n",
    "    normalized_scores = normalize(arr=_results['scores'], t_max=_results['weight'])\n",
    "    print(normalized_scores)\n",
    "    for id, score in zip(_results['ids'], normalized_scores):\n",
    "        # Case where product is already recommended by one or more other models\n",
    "        if id in ensemble_results:\n",
    "            ensemble_results[id] += score # Add the score to the previous value\n",
    "            ensemble_results[id] /= 2 # Average the score (This is a rough average)\n",
    "        # Case where product is already recommended first time by current model\n",
    "        else:\n",
    "            ensemble_results[id] = score\n",
    "    \n",
    "ensemble_results = sort_by_score(ensemble_results)\n",
    "ensemble_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70da2795-1dba-431f-913c-ce58f910af1c",
   "metadata": {},
   "source": [
    "### Inference - Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "5185879f-4f5d-488f-839c-cbe60c565164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BPR': {'weight': 0.2},\n",
       " 'ALS': {'weight': 0.8},\n",
       " 'BM25': {'weight': 1.0},\n",
       " 'ENSEMBLE': {'weight': 1}}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = {}\n",
    "results[\"BPR\"] = {\"weight\": BPR_WEIGHT}\n",
    "results[\"ALS\"] = {\"weight\": ALS_WEIGHT}\n",
    "results[\"BM25\"] = {\"weight\": BM25_WEIGHT}\n",
    "results[\"ENSEMBLE\"] = {\"weight\": 1}\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "63666d6f-b1d4-4795-b534-73e6b9c4bfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update weights\n",
    "results[\"BPR\"][\"weight\"] = BPR_WEIGHT\n",
    "results[\"ALS\"][\"weight\"] = ALS_WEIGHT\n",
    "results[\"BM25\"][\"weight\"] = BM25_WEIGHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "49c098a3-8b47-475e-8c29-572a7e7ef1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_coo = test_csr.tocoo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f85b88e-e85f-4b74-a990-b318f1092dcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "actual_dict = {}\n",
    "eval_dict = {\"precision\": [], \"recall\": [], \"f1_score\": []}\n",
    "for user_id, product_id, rating in zip(test_coo.row, test_coo.col, test_coo.data):\n",
    "    # print(f\"Processing: user_id: {user_id}, product_id: {product_id}, rating: {rating}\")\n",
    "    print(user_id, end = ', ')\n",
    "    # Retrieve actual products and ratings\n",
    "    if user_id in actual_dict:\n",
    "        actual_dict[user_id].append(product_id)\n",
    "    else:\n",
    "        actual_dict[user_id] = [product_id]\n",
    "\n",
    "    # Get recommendation from each model\n",
    "    ids, scores = BPR_model.recommend(user_id, test_csr[user_id], N=K, filter_already_liked_items=False)\n",
    "    results[\"BPR\"][user_id] = {\"product_ids\": list(ids), \"scores\": list(scores)}\n",
    "    \n",
    "    ids, scores = ALS_model.recommend(user_id, test_csr[user_id], N=K, filter_already_liked_items=False)\n",
    "    results[\"ALS\"][user_id] = {\"product_ids\": list(ids), \"scores\": list(scores)}\n",
    "\n",
    "    ids, scores = BM25_model.recommend(user_id, test_csr[user_id], N=K, filter_already_liked_items=False)\n",
    "    results[\"BM25\"][user_id] = {\"product_ids\": list(ids), \"scores\": list(scores)}\n",
    "\n",
    "    # Ensemble results\n",
    "    ensemble_results = {}\n",
    "    for _model, _results in results.items():\n",
    "        if _model == \"ENSEMBLE\":\n",
    "            continue\n",
    "        scores = _results[user_id]['scores']\n",
    "        # Check if all product scores are equal or empty\n",
    "        if len(set(scores)) <= 1:\n",
    "            print(f\"Skipping Model: {_model}, User Id: {user_id}\")\n",
    "            continue\n",
    "        # Score is normalized to range 0-1 and then weighted by the specified model weight \n",
    "        normalized_scores = normalize(arr=scores, t_max=_results['weight'])\n",
    "        # print(\"Normalized scores: \", normalized_scores)\n",
    "        for id, score in zip(_results[user_id]['product_ids'], normalized_scores):\n",
    "            # Case where product is already recommended by one or more other models\n",
    "            if id in ensemble_results:\n",
    "                ensemble_results[id] += score # Add the score to the previous value\n",
    "                ensemble_results[id] /= 2 # Average the score (This is a rough average)\n",
    "            # Case where product is recommended first time by current model\n",
    "            else:\n",
    "                ensemble_results[id] = score\n",
    "        \n",
    "    ensemble_results = sort_by_score(ensemble_results)\n",
    "    results[\"ENSEMBLE\"][user_id] = {\"product_ids\": list(ensemble_results.keys()), \"scores\": list(ensemble_results.values())}\n",
    "\n",
    "    # Evaluate ensemble results\n",
    "    actual_products = actual_dict[user_id]\n",
    "    ensemble_products = results[\"ENSEMBLE\"][user_id][\"product_ids\"]\n",
    "    eval_dict[\"precision\"].append(precision_at_k(actual_products, ensemble_products, K))\n",
    "    eval_dict[\"recall\"].append(recall_at_k(actual_products, ensemble_products, K))\n",
    "    eval_dict[\"f1_score\"].append(f1_acore_at_k(actual_products, ensemble_products, K))\n",
    "    \n",
    "    # break\n",
    "# print(\"Actual: \", actual_dict)\n",
    "# print(\"Predicted: \", results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "8a9565c2-43ec-47a9-bb93-be35b224db25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble recommendation results -------\n",
      "Precision at K:  0.11708476438391417\n",
      "Recall at K:  0.8168642918650342\n",
      "F1 score at K:  0.1932667989134614\n"
     ]
    }
   ],
   "source": [
    "print(\"Ensemble recommendation results -------\")\n",
    "print(\"Precision at K: \", statistics.fmean(eval_dict[\"precision\"]))\n",
    "print(\"Recall at K: \", statistics.fmean(eval_dict[\"recall\"]))\n",
    "print(\"F1 score at K: \", statistics.fmean(eval_dict[\"f1_score\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b58bd8-7c8d-4df8-ba69-5766a40cb320",
   "metadata": {},
   "source": [
    "Results with equal weights:\n",
    "Ensemble recommendation results -------\n",
    "Precision at K:  0.1151417438713989\n",
    "Recall at K:  0.879726517120218\n",
    "F1 score at K:  0.19492122310857204\n",
    "\n",
    "Ensemble recommendation results -------\n",
    "BPR_WEIGHT = 0.2\n",
    "ALS_WEIGHT = 0.8\n",
    "BM25_WEIGHT = 1.0\n",
    "Precision at K:  0.11551102115150497\n",
    "Recall at K:  0.878208357795375\n",
    "F1 score at K:  0.19484041665986454\n",
    "\n",
    "Ensemble recommendation results -------\n",
    "BPR_WEIGHT = 0.5\n",
    "ALS_WEIGHT = 0.8\n",
    "BM25_WEIGHT = 1.0\n",
    "Precision at K:  0.13576925361020659\n",
    "Recall at K:  0.8605703087110153\n",
    "F1 score at K:  0.21659103398676482\n",
    "\n",
    "Ensemble recommendation results -------\n",
    "BPR_WEIGHT = 1.0\n",
    "ALS_WEIGHT = 0.8\n",
    "BM25_WEIGHT = 1.0\n",
    "Precision at K:  0.13087308107252085\n",
    "Recall at K:  0.8501083804301565\n",
    "F1 score at K:  0.21067435575404123\n",
    "\n",
    "Ensemble recommendation results -------\n",
    "BPR_WEIGHT = 0.5\n",
    "ALS_WEIGHT = 0.5\n",
    "BM25_WEIGHT = 1.0\n",
    "Precision at K:  0.13801208516029415\n",
    "Recall at K:  0.8653632971405383\n",
    "F1 score at K:  0.21932993484321203\n",
    "\n",
    "Ensemble recommendation results -------\n",
    "BPR_WEIGHT = 0.5\n",
    "ALS_WEIGHT = 0.2\n",
    "BM25_WEIGHT = 1.0\n",
    "Precision at K:  0.14197440440252196\n",
    "Recall at K:  0.873360684132907\n",
    "F1 score at K:  0.22403032030382244\n",
    "\n",
    "Ensemble recommendation results -------\n",
    "BPR_WEIGHT = 0.5\n",
    "ALS_WEIGHT = 0\n",
    "BM25_WEIGHT = 1.0\n",
    "Precision at K:  0.14482198885512657\n",
    "Recall at K:  0.881021547415201\n",
    "F1 score at K:  0.2278665552786446\n",
    "\n",
    "Ensemble recommendation results -------\n",
    "BPR_WEIGHT = 0\n",
    "ALS_WEIGHT = 0\n",
    "BM25_WEIGHT = 1.0\n",
    "Precision at K:  0.15390416992467806\n",
    "Recall at K:  0.8944998168915107\n",
    "F1 score at K:  0.23739280949092406\n",
    "\n",
    "Ensemble recommendation results -------\n",
    "BPR_WEIGHT = 1\n",
    "ALS_WEIGHT = 1\n",
    "BM25_WEIGHT = 0.5\n",
    "Precision at K:  0.11708476438391417\n",
    "Recall at K:  0.8168642918650342\n",
    "F1 score at K:  0.1932667989134614"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "09d81cd7-b832-4388-8ccd-7a469b45e6d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224212"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(actual_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "31e70740-9b2f-4841-9cad-27642b908465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretty print\n",
    "def pretty(d, indent=0):\n",
    "   for key, value in d.items():\n",
    "      print('\\t' * indent + str(key))\n",
    "      if isinstance(value, dict):\n",
    "         pretty(value, indent+1)\n",
    "      else:\n",
    "         print('\\t' * (indent+1) + str(value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b89285-de6a-479a-9265-94413610ac63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pretty(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "cc7273f0-e4a6-478e-9a49-6fea39a5a3e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"BPR\"][\"weight\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5df6d2-37b0-4bda-a7e8-97af584b729f",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "de308ec5-5534-4498-b690-57becfaf81f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_error(actual, predicted):\n",
    "    return np.abs(actual - predicted).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2bffd90b-e745-4c49-8c9e-024ceb02486c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_square_error(actual, predicted):\n",
    "    return np.sqrt(((actual - predicted)**2)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "223446ef-d33a-44ae-8f7c-477a4e10797e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(actual, predicted, k):\n",
    "    return len(\n",
    "        set(actual) & set(predicted[:k])\n",
    "    )/k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e839f5f2-b3f9-4354-85f1-cdf830c49cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_at_k(actual, predicted, k):\n",
    "    return len(\n",
    "        set(actual) & set(predicted[:k])\n",
    "    )/len(actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9cd63bef-74da-4efc-b63a-2a4e765c5c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_acore_at_k(actual, predicted, k):\n",
    "    p = precision_at_k(actual, predicted, k)\n",
    "    r = recall_at_k(actual, predicted, k)\n",
    "    if p + r == 0:\n",
    "        return 0\n",
    "    return 2*(p*r)/(p+r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "55e1b395-8d35-4016-8d0f-5b36ce04376c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndcg_at_k():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38784e0-91fe-4d81-8bed-a5308044ea2d",
   "metadata": {},
   "source": [
    "### Temp section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "853b78dc-0113-4d9c-98c6-ceb35aba4405",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7977ff-578f-4592-89c2-87302854cc59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rec-sys-py3.11",
   "language": "python",
   "name": "rec-sys-py3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
